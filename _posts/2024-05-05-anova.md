---
title: "ANOVA"

categories:
  - datascience

---
## Summary
- 일원분산분석 : scipy.stats.f_oneway
- 이원분산분석 : statsmodels.formula.api.ols, statsmodels.api.anova_lm
  
![Validation](/assets/images/anova.jpg){:width="900px" height="400px"}{: .center}

## Code

![Validation](/assets/images/anovacode.PNG){:width="500px" height="400px"}{: .center}


```python
# 내 답안
from scipy.stats import f_oneway

df_ind['factor'].unique()
a = df_ind.loc[df_ind['factor']=='A', 'X']
b = df_ind.loc[df_ind['factor']=='B', 'X']
c = df_ind.loc[df_ind['factor']=='C', 'X']

f, p = f_oneway(a,b,c)
# F_onewayResult(statistic=0.27566921886248474, pvalue=0.7597245063787699)

# 확장 가능한 답안 (그룹이 많아졌을 때 사용 가능)
df_ind.groupby('factor')['X'].agg(list) # series
f_oneway(*df_ind.groupby('factor')['X'].agg(list)) 
# * : argument unpacking 연산자로 iterable 데이터를 분해하여 함수 인자로 전달

# (
#     [그룹1의 X 값들],
#     [그룹2의 X 값들],
#     [그룹3의 X 값들],
#     ...
# )
```

- **라이브러리 사용하지 않고 직접 구현하는 방법**

```python
from scipy.stats import f
def ss (v):
  return (v**2).sum()

#SSA = ss(df_ind.groupby('factor')['X'].apply(lambda x : x.mean()) - df_ind['X'].mean()) # 틀림 -> !!!각 treatment 마다 관측치 개수를 곱해줘야 함!!!
SSA = ss(df_ind.groupby('factor')['X'].transform('mean') - df_ind['X'].mean())
SSE = ss(df_ind.groupby('factor')['X'].transform(lambda x : x - x.mean()))
SST = ss(df_ind['X']-df_ind['X'].mean())

df_ssa = df_ind['factor'].nunique() - 1
df_sst = len(df_ind) - 1
df_sse = df_sst - df_ssa

F = (SSA/df_ssa) / (SSE/df_sse)
pvalue = 1 - f.cdf(F, df_ssa, df_sse) # 0.7597245063787699
```

## ANOVA 조건 확인 검증 코드 - 1. 정규성 검정



## ANOVA (Analysis of Variance, 분산분석)
- ANOVA 는 ? 가설검정 방법이다!
- 변수가 2개일 경우(표본 데이터셋이 2개) 평균 차이를 검증할 때, t-test 검정을 한다.
- 변수가 **2개 이상일** 경우 ANOVA 를 활용한다.
  - ANOVA 에서의 모집단 : population, level, treatment
- 평균 차이 검정인데 왜 분산 분석?
  - 분산 : 평균 근처에서 얼마나 많이 흩어져 있는가?
  - **집단 내 분산과 각 집단 간의 평균의 분산을 이용해서 평균이 같은지 다른지를 확인하는 방법이다!**
  - **만약 집단 간의 평균의 차이가 크고 집단 내 분산은 작다면, 각 집단의 평균은 확실히 다르다고 말할 수 있다.**


![Validation](/assets/images/anova6.PNG){:width="900px" height="400px"}{: .center}

- Yij : 관측하는 값
- mui : true mean
- errorij : 정규분포를 따르는 error 


![Validation](/assets/images/anova7.PNG){:width="900px" height="400px"}{: .center}

- k : treatment, level 의 개수
- n : sample 의 개수


## F 분포
- F 가 나오면 무조건 분산 분석.
- **F(총변동) = 그룹간 변동 / 그룹내 변동**
  - 그룹간 변동 : 전체 평균과 각 그룹간의 평균이 얼마나 떨어져있는지
  - 그룹내 변동 : 각 그룹 안에서의 분산

## ANOVA 가설
- 귀무가설 : **모든 그룹의 평균이 같다.**
- 대립가설 : 어떤 그룹의 평균은 같지 않다. -> at least two of the factor level means are not equal
- 여러 그룹 간에 평균이 다른 그룹이 있다. -> 어떤 그룹인지 찾아낼 수는 없다.
  - 그게 누군지 알고 싶으면 사후 검정이 필요하다. 


## ANOVA 가정
  - 정규분포, 등분산, 독립성
  - K개의 그룹은 정규분포를 이룬다.
  - 모든 그룹은 등분산이다. -> 사전에 등분산 검정이 필요하다.
  - K개의 그룹은 서로 독립이다.
  - + K개의 그룹으로 된 모집단의 자료는 **연속형**이다.

- 그룹간의 분산은 클수록 좋다. 그룹간 경계가 명확하니까. 반대로 그룹내의 분산은 작을수록 평균값 근처에서 모두 똘똘 뭉치므로 좋다.
- SSE(Sum of squared error) : 각 그룹별로 그룹 내 평균값과 관측값들의 차이로 SSE 값 계산 가능하다.
- SSTR : 그룹들을 전체로 보면 전체에 대한 평균이 있고, 각 그룹간의 평균이 있을 때 그들간의 차이를 제곱해서 더한다.
  
![Validation](/assets/images/ANOVA.PNG){:width="900px" height="400px"}{: .center}

- SSTR 구할 때 n을 곱해줘야 한다.

![Validation](/assets/images/onewayanova.PNG){:width="900px" height="400px"}{: .center}

![Validation](/assets/images/anova8.PNG){:width="900px" height="400px"}{: .center}

- total sum of squares (SST)
  - yij : i번째 level의 j번째 관측치
  - y dot dot bar : 전체 평균
  - df : nk - 1 (n : 관측치 개수, k : level 개수)
- level sum of squares **(SSA)**
  - yi dot bar : i번째 level의 전체 평균
  - **level 간의 차이**가 있는지를 보는 것.
  - df : k - 1 
- error sum of squares **(SSE)**
  - **level 내에서의 차이**가 있는지를 보는 것.
  - df : df(SST) - df(SSA) = k(n-1)
- **SSA >> SSE 이면 level 간의 차이가 크다고 할 수 있다.**
- SSA < SSE 이면 level 간의 차이가 크다고 보기 어렵다. 

- 표본분산은 카이제곱분포를 따른다. -> **SST, SSA, SSE** 도 큰 의미에서는 평균과 관측값의 차이이므로 **카이제곱분포**를 따른다.


## 분산분석표
- factor? treatment?
  - factor : 관측값에 영향을 주는 속성인 요인, treatment : 각 요인 내의 처리방식
  - e.g., factor : 휘발유, treatment : 휘발유의 종류 3가지
- factor 가 1개이면 일원분산분석이라고 한다. (One-way ANOVA)
- factor 개수에 따라서 two-way, three-way ANOVA


![Validation](/assets/images/ANOVA2.PNG){:width="900px" height="400px"}{: .center}

- MSA/MSE 통계량은 F분포를 따른다.

## 사후검정
- 귀무가설이 기각된 경우 어떤 그룹의 평균이 다른 가에 대한 설명은 제시하지 않으므로 사후검정이 필요하다.
  - **Tukey**
  - Bonferroni
  - Scheffe
  - Duncan


## 예제 문제
- 3가지 브랜드의 자동차 타이어가 있을 때, 각 타이어의 성능비교를 위해 각각 제동거리 5회 측정(m)하였다.
이를 토대로 타이어 종류에 따라 제동거리의 차이가 있는지 유의 수준 1%로 검정하라.

![Validation](/assets/images/anova3.PNG){:width="900px" height="400px"}{: .center}

- factor : 타이어, treatement : A, B, C 타이어
- 귀무가설 : 집단 간 평균의 차이가 없다.
- 대립가설 : 집단 간 평균의 차이가 있다. 각 브랜드 별 타이어의 성능 차이가 있다.
- SST(총변동성) = SSE + SSTR
  

![Validation](/assets/images/ANOVA4.PNG){:width="900px" height="400px"}{: .center}

![Validation](/assets/images/anova5.PNG){:width="900px" height="400px"}{: .center}

- P-value < alpha(유의수준) 이므로 귀무가설을 기각한다. 타이어 브랜드 별 차이가 있다.


## 예제 문제 2

![Validation](/assets/images/ANOVAEX.PNG){:width="900px" height="400px"}{: .center}


![Validation](/assets/images/ANOVAEX2.PNG){:width="900px" height="400px"}{: .center}

- 유의수준 0.05 에서 검증하는 것이므로 p value < 0.05 이므로 귀무가설을 기각한다.

## 이원분산분석
- 상호작용, 교호작용 (interaction)
  - A의 효과가 B의 서로 다른 수준인 B1, B2 에서 일관성있게 나타난다면 두 인자 A, B 간의 교호작용은 없다고 한다.
  - 만일 B1 수준일 때 A 의 효과와 B2 수준일 때 A의 효과가 차이가 있다면, A, B 간의 교호작용이 존재한다.

![Validation](/assets/images/interaction.PNG){:width="900px" height="400px"}{: .center}

## 이원분산분석 예제 코드

- 이원분산분석은 statsmodels 라이브러리를 활용해야 한다.
- 문제 : df_two에서 X에 대한 factor1, factor2의 이원분산분석을 해봅니다.

![Validation](/assets/images/twowayanova.PNG){:width="300px" height="200px"}{: .center}

```python
from statsmodels.formula.api import ols
from statsmodel.api import stats

lm = ols('X ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', data=df_two).fit()
df_anova = stats.anova_lm(lm)
df_anova
```

![Validation](/assets/images/dfanova.PNG){:width="900px" height="400px"}{: .center}

- alpha 유의수준 = 0.05 일 때, 
- factor_1 의 효과는 유의미하지 않다. (pvalue = 0.845)
- factor_2 의 효과는 유의미하지 않다. (pvalue = 0.078)
- factor_1 과 factor_2 의 상호작용의 효과는 있다. (pvalue = 0.002)