---
title: "Imbalanced Data"

categories:
  - datascience

---

## Imbalanced data
- 정확도가 높아도 재현율이 떨어지는 문제가 발생한다.
  - 100개의 데이터 중 3개가 음성이면, 모두 양성이라 예측해도 정확도가 97%이기 때문이다.
- 1. 언더샘플링
  - 다수 클래스의 샘플을 줄이는 방법
  - 정보 손실 가능성
- 2. 오버샘플링
  - 소수 클래스의 샘플을 생성하는 방법
  - 정보 손실은 없으나, overfitting 가능성
- 

## SMOTE
- synthetic minority over-sampling technique
- 클래스 불균형을 해결하기 위한 **오버샘플링** 기법 중 하나
- 소스 클래스의 샘플을 생성하여 데이터셋을 균형있게 만드는 방법


## SMOTE 동작 과정
1. 소수 클래스의 샘플 선택한다. (KNN 활용)
   1. 소수 클래스에 속하는 각 샘플에 대해 그 샘플과 가장 가까운 이웃들을 찾는다.
   2. 이웃은 보통 주변의 가장 가까운 k개의 이웃 중에서 선택한다. (k : hyperparameter)
2. 샘플을 생성한다.
   1. 샘플 s와 그 이웃 중 하나를 선택한다.
   2. 이 두 점을 잇는 선 상의 어떤 지점을 선택해 새로운 합성 샘플을 생성한다.
   3. 이 지점의 위치는 기존 샘플과 이웃 사이의 거리에 비례한다. 
3. 샘플을 추가한다.

